import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset


# =========================================================
# 1. æ—¥çº§å¤©æ°” Datasetï¼šè¯»å– CSVã€ç­›é€‰åŸå¸‚ã€æ¸…æ´— NaN/Infã€æ ‡å‡†åŒ–
# =========================================================
class DailyWeatherDataset(Dataset):
    """
    è¯»å–æ—¥çº§å¤©æ°”æ•°æ®ï¼Œåªä¿ç•™ San Francisco å’Œ New Yorkï¼Œ
    ä½¿ç”¨ä½ ç­›é€‰è¿‡çš„ 18 ä¸ªç‰¹å¾ï¼Œæ¸…æ´—æ‰å« NaN/Inf çš„è¡Œï¼Œç„¶åæ ‡å‡†åŒ–ã€‚
    """

    def __init__(
        self,
        csv_path="./dataset_global/weather_daily_global.csv",
        cities=("San Francisco", "New York"),
        date_col="time",   # ä½ çš„æ—¥æœŸåˆ—å
    ):
        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ—¥çº§æ•°æ®æ–‡ä»¶: {csv_path}")

        # 1) è¯»å– CSV
        df = pd.read_csv(csv_path)

        # 2) æ£€æŸ¥å¿…é¡»åˆ—ï¼šcity + æ—¥æœŸåˆ—
        required_cols = ["city", date_col]
        for c in required_cols:
            if c not in df.columns:
                raise KeyError(f"âŒ CSV ä¸­ç¼ºå°‘å¿…é¡»åˆ—: {c}")

        # 3) åªä¿ç•™ä¸¤ä¸ªåŸå¸‚
        df = df[df["city"].isin(cities)].copy()
        if df.empty:
            raise RuntimeError(f"âŒ CSV ä¸­æ²¡æœ‰æ‰¾åˆ°åŸå¸‚ {cities} çš„æ•°æ®")

        # 4) å¤„ç†æ—¥æœŸï¼šç»Ÿä¸€æˆ df["date"]
        df["date"] = pd.to_datetime(df[date_col])
        df = df.sort_values(["city", "date"]).reset_index(drop=True)

        # 5) ç›®æ ‡åˆ—
        target_col = "precipitation_sum_mm"

        # 6) ç‰¹å¾åˆ—ï¼šä½ ç›¸å…³æ€§åˆ†æåé€‰çš„ 18 ä¸ª
        feature_cols = [
            "temp_mean_C",
            "temp_max_C",
            "temp_min_C",
            "rh_mean_pct",
            "press_mean_hPa",
            "wind_mean_ms",
            "wind_dir_deg",
            "cloud_mean_pct",
            "dew_point_C",
            "month",
            "month_sin",
            "month_cos",
            "precip_lag_1",
            "precip_lag_3",
            "temp_mean_lag_1",
            "precip_roll7",
            "lat",
            "lon",
        ]

        for c in feature_cols + [target_col]:
            if c not in df.columns:
                raise KeyError(f"âŒ CSV ç¼ºå°‘åˆ—: {c}")

        # 7) å…ˆå¤„ç† NaN / Infï¼šåˆ é™¤å« NaN/Inf çš„æ ·æœ¬
        cols_to_check = feature_cols + [target_col]
        df[cols_to_check] = df[cols_to_check].replace([np.inf, -np.inf], np.nan)
        before = len(df)
        df = df.dropna(subset=cols_to_check).reset_index(drop=True)
        after = len(df)
        dropped = before - after
        print(f"ğŸ§¹ å·²å»é™¤å« NaN/Inf çš„è¡Œ: {dropped} è¡Œï¼Œå‰©ä½™ {after} è¡Œ")

        # 8) ä¿å­˜é…ç½®
        self.feature_cols = feature_cols
        self.target_col = target_col

        # 9) å¯¹ç‰¹å¾åšæ ‡å‡†åŒ–
        self.mean = df[feature_cols].mean()
        self.std = df[feature_cols].std().replace(0, 1e-6)
        df[feature_cols] = (df[feature_cols] - self.mean) / (self.std + 1e-6)

        self.df = df.reset_index(drop=True)

        print("âœ… DailyWeatherDataset åˆå§‹åŒ–å®Œæˆï¼ˆæ¸…æ´—åï¼‰")
        print(f"   âœ” åŸå¸‚: {sorted(self.df['city'].unique())}")
        print(f"   âœ” æ€»å¤©æ•°: {len(self.df)}")
        print(f"   âœ” ç‰¹å¾ç»´åº¦: {len(self.feature_cols)}")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        x = torch.tensor(row[self.feature_cols].astype(float).values, dtype=torch.float32)
        y = torch.tensor(float(row[self.target_col]), dtype=torch.float32)
        city = row["city"]
        date = row["date"]
        return x, y, city, date


# =========================================================
# 2. åºåˆ— Datasetï¼šè¿‡å» lookback å¤© â†’ æ˜å¤© (log1p)
# =========================================================
class DailySequenceDataset(Dataset):
    """
    æŠŠ DailyWeatherDataset è½¬æˆåºåˆ—ï¼š
        è¾“å…¥ï¼šè¿‡å» lookback å¤©çš„ç‰¹å¾ï¼ˆä¾‹å¦‚ 30 å¤©ï¼‰
        è¾“å‡ºï¼šç›®æ ‡é‚£å¤©çš„ log1p(é™é›¨é‡)
    """

    def __init__(self, daily_ds: DailyWeatherDataset, lookback=30):
        self.daily_ds = daily_ds
        self.feature_cols = daily_ds.feature_cols
        self.target_col = daily_ds.target_col
        self.lookback = lookback

        df = daily_ds.df
        self.df = df

        self.samples = []  # (city, start_idx, end_idx)

        for city, df_city in df.groupby("city"):
            idxs = df_city.index.to_list()
            if len(idxs) <= lookback:
                continue
            for i in range(lookback, len(idxs)):
                start = idxs[i - lookback]
                end = idxs[i]
                self.samples.append((city, start, end))

        print("âœ… DailySequenceDataset åˆå§‹åŒ–å®Œæˆ")
        print(f"   âœ” lookback = {lookback} å¤©")
        print(f"   âœ” åºåˆ—æ ·æœ¬æ•°: {len(self.samples)}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        city, start, end = self.samples[idx]

        window = self.df.loc[start:end-1, self.feature_cols].values.astype("float32")
        target = float(self.df.loc[end, self.target_col])  # mm

        x = torch.tensor(window, dtype=torch.float32)
        y_log = torch.tensor(np.log1p(target), dtype=torch.float32)

        # è®­ç»ƒæ—¶åªéœ€è¦ x, y_log
        return x, y_log


# =========================================================
# 3. æµ‹è¯• usage
# =========================================================
if __name__ == "__main__":
    print("ğŸ§ª æ­£åœ¨æµ‹è¯• DailyWeatherDataset å’Œ DailySequenceDataset ...")

    daily_ds = DailyWeatherDataset(
        csv_path="./dataset_global/weather_daily_global.csv",
        cities=("San Francisco", "New York"),
        date_col="time",
    )

    print("\nğŸ” æŸ¥çœ‹ä¸€æ¡å•å¤©æ ·æœ¬ï¼š")
    x0, y0, c0, d0 = daily_ds[0]
    print(f"   åŸå¸‚: {c0}, æ—¥æœŸ: {d0.date()}, é›¨é‡: {y0.item():.3f} mm")
    print(f"   ç‰¹å¾ç»´åº¦: {x0.shape}")

    seq_ds = DailySequenceDataset(daily_ds, lookback=30)

    print("\nğŸ” æŸ¥çœ‹ä¸€æ¡åºåˆ—æ ·æœ¬ï¼š")
    x1, y1 = seq_ds[0]
    print(f"   X å½¢çŠ¶: {x1.shape} (åº”ä¸º [30, ç‰¹å¾æ•°])")
    print(f"   y_log: {y1.item():.4f}")
    print("ğŸ‰ Dataset æµ‹è¯•é€šè¿‡ï¼")
